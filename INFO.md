## Notes
* Will be using gpt-neo


## TODO
* Write Trainer class
  * Read up on Data Collators for text generation
* Check warning messages for Cuda etc
* Read up on DeepSpeed
* Gather more data 
* Add scheduler?


## Data Collection
Books/writing of Tolkien to collect
* Unfinished Tales of Numenor
* The History of Middle Earth (1-12)
* The Children of Hurin
* Beren and Luthien


## Useful links

* Example of fine tuning gpt-neo:
  * https://github.com/dredwardhyde/gpt-neo-fine-tuning-example/blob/main/gpt_neo.py

* Full guide:
  * https://towardsdatascience.com/guide-to-fine-tuning-text-generation-models-gpt-2-gpt-neo-and-t5-dc5de6b3bc5e


* How to Fine-Tune GPT-2 For Text Generation
  * https://towardsdatascience.com/how-to-fine-tune-gpt-2-for-text-generation-ae2ea53bc272

* Fine-tuning GPT-2 on Harry Potter texts for free
  * https://medium.com/@manjeetsingh_37967/fine-tuning-gpt-2-on-harry-potter-texts-for-free-718e9959aa89

* Fine Tuning GPT-2 for Magic the Gathering Flavour Text Generation
  * https://medium.com/swlh/fine-tuning-gpt-2-for-magic-the-gathering-flavour-text-generation-3bafd0f9bb93

* Fine-tuning GPT2 for Text Generation Using Pytorch
  * https://towardsdatascience.com/fine-tuning-gpt2-for-text-generation-using-pytorch-2ee61a4f1ba7


* Similar example
  * https://github.com/parvathysarat/gpt2-text-generation

